# -*- coding: utf-8 -*-
"""EnsembleCNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IShvC8JUKDhG2npY5vlLMrj3Lwy5XFjw
"""

import pandas as pd
import numpy as np 
import matplotlib.pyplot as plt
from keras.datasets import mnist
from tensorflow import keras
import tensorflow as tf

"""#Purpose

To take the most common output of N neural networks and that is the output we will choose for the prediction of an input.
"""

class Ensemble_CNN():

  def __init__(self, num_networks: int, network_layer_depths: list, network_layer_lr: list, epochs: list, num_classes=10, input_shape=(28, 28, 1)):
    '''
    Init method for ensemble methods. Generates CNN objects into list. Must be trained with
    trainer method. Once trained can be used to predict a singular output or list of outputs.
    @param num_networks: # of networks that will be used for prediction.
    @param network_layer_depths: List of the depth of each model. (# of conv2d, pool, and batch layers).
    Should be same length as layer and epochs list.
    @param network_layer_lr: List of learning rates for each model
    @param num_classes: Number of class labels.
    @param input shape: Shape of input data.
    '''
    assert(len(epochs) == len(network_layer_depths) == len(network_layer_lr))
    self.num_classes = num_classes
    self.num_networks = num_networks
    self.network_layers = network_layer_depths
    self.learning_rates = network_layer_lr
    self.epochs = epochs
    self.shape = input_shape
    self.networks = self.generate_networks()

  def generate_networks(self):
    '''
    Generates N (num_networks) networks with different specified layer depths 
    and learning rates. 
    @return list of network objects ready for training
    '''
    networks = []
    for n in range(self.num_networks):
      model = keras.Sequential(name=('model_' + str(n)))
      for l in range(self.network_layers[n]):
        model.add(keras.layers.Conv2D(32, kernel_size=2, activation='relu', input_shape=self.shape))
        model.add(keras.layers.MaxPooling2D((2,2), strides=2))
        model.add(keras.layers.BatchNormalization())
      
      model.add(keras.layers.Flatten())
      model.add(keras.layers.Dense(10, activation='relu'))
      model.add(keras.layers.Dense(10, activation='softmax'))

      networks.append(model)
    
    return networks

  def train(self, x_data, labels):
    '''
    For each model, train it with the given data. Use the learning rates and
    epochs provided.
    @param x_data: Labeless data for training on.
    @param labels: Corresponding labels to the x_data.
    '''

    for idx, m in enumerate(self.networks):
        print('Training Model ' + str(idx))
        loss_fn = keras.losses.CategoricalCrossentropy()
        opt=keras.optimizers.SGD(learning_rate=self.learning_rates[idx])

        m.compile(loss=loss_fn, optimizer=opt)

        m.fit(x_data, labels, epochs=self.epochs[idx], verbose=0)


  def predict(self, x_data):
    '''
    Predict each element of dataset. Prediction is based on the most common output
    from each model.
    @param x_data: Labeless data to predict from.
    @return list of predictions.
    '''
    predictions = []
    for m in enumerate(self.networks):
      pred = m.predict(x_data)
      predictions.append(pred)

    final_preds = []
    for n in range(len(x_data)):
      preds = [np.argmax(predictions[i][n]) for i in range(self.num_networks)]
      final_preds.append(np.bincount(preds).argmax())
    
    return final_preds

  def evaluate(self, preds, truth):
    '''
    Calculates the accuracy of the model.
    @param preds: Predictions of model. From predict method.
    @param truth: True labels of the predictions
    '''
    acc = 100 * np.sum(preds==truth) / len(truth)
    print('Accuracy: ' + str(acc))

layers = [1, 1, 2, 2, 3]
lrs = [5e-5, 5e-5, 5e-4, 5e-4, 5e-3]
epochs = [75, 75, 60, 60, 50]
models = Ensemble_CNN(5, layers, lrs, epochs)

(train_X, train_y), (test_X, test_y) = mnist.load_data()
onehot_train_y = keras.utils.to_categorical(train_y, 10)
onehot_test_y = keras.utils.to_categorical(test_y, 10)

models.train(train_X, onehot_train_y)

preds = models.predict(test_X)

models.evaluate(preds, test_y)